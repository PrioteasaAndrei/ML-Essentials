{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODOS\n",
    "\n",
    "- check that the forward pass of the dropout model is implemented correctly (there is something called inverse dropout and some weird scaling) incearca cele doua noi\n",
    "- verifica ca la lenet + shift chiar e ok valuarea aia si nu ai stricat tu ceva e prea mica. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.nn.functional import conv2d, max_pool2d, cross_entropy\n",
    "\n",
    "plt.rc(\"figure\", dpi=100)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BASE_MODEL = False\n",
    "TRAIN_DROPOUT_MODEL = True\n",
    "TRAIN_PRELU_MODEL = False\n",
    "TRAIN_LENET = False\n",
    "TRAIN_LENET_SHIFT = False\n",
    "\n",
    "ALL = TRAIN_BASE_MODEL and TRAIN_DROPOUT_MODEL and TRAIN_PRELU_MODEL and TRAIN_LENET and TRAIN_LENET_SHIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "# transform images into normalized tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "transform_extended = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "]) \n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    \"./\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    \"./\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    # Kaiming He initialization (a good initialization is important)\n",
    "    # https://arxiv.org/abs/1502.01852\n",
    "    std = np.sqrt(2. / shape[0])\n",
    "    w = torch.randn(size=shape).to(device) * std\n",
    "    w.requires_grad = True\n",
    "    return w\n",
    "\n",
    "\n",
    "def rectify(x):\n",
    "    # Rectified Linear Unit (ReLU)\n",
    "    return torch.max(torch.zeros_like(x), x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSprop(optim.Optimizer):\n",
    "    \"\"\"\n",
    "    This is a reduced version of the PyTorch internal RMSprop optimizer\n",
    "    It serves here as an example\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr=1e-3, alpha=0.5, eps=1e-8):\n",
    "        defaults = dict(lr=lr, alpha=alpha, eps=eps)\n",
    "        super(RMSprop, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self):\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                grad = p.grad.data.to(device)\n",
    "                state = self.state[p]\n",
    "\n",
    "                # state initialization\n",
    "                if len(state) == 0:\n",
    "                    state['square_avg'] = torch.zeros_like(p.data)\n",
    "\n",
    "                square_avg = state['square_avg']\n",
    "                alpha = group['alpha']\n",
    "\n",
    "                # update running averages\n",
    "                square_avg.mul_(alpha).addcmul_(grad, grad, value=1 - alpha)\n",
    "                avg = square_avg.sqrt().add_(group['eps'])\n",
    "\n",
    "                # gradient update\n",
    "                p.data.addcdiv_(grad, avg, value=-group['lr'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the neural network\n",
    "def model(x, w_h, w_h2, w_o):\n",
    "    h = rectify(x @ w_h)\n",
    "    h2 = rectify(h @ w_h2)\n",
    "    pre_softmax = h2 @ w_o\n",
    "    return pre_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_BASE_MODEL:\n",
    "\n",
    "    # initialize weights\n",
    "    # input shape is (B, 784)\n",
    "    w_h = init_weights((784, 625))\n",
    "    # hidden layer with 625 neurons\n",
    "    w_h2 = init_weights((625, 625))\n",
    "    # hidden layer with 625 neurons\n",
    "    w_o = init_weights((625, 10))\n",
    "    # output shape is (B, 10)\n",
    "\n",
    "\n",
    "    optimizer = RMSprop(params=[w_h, w_h2, w_o])\n",
    "\n",
    "    train_loss = []\n",
    "    test_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_BASE_MODEL:\n",
    "    # put this into a training loop over 100 epochs\n",
    "    for epoch in range(n_epochs + 1):\n",
    "        train_loss_this_epoch = []\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            x, y = batch\n",
    "\n",
    "            # our model requires flattened input\n",
    "            x = x.reshape(batch_size, 784).to(device)\n",
    "            # feed input through model\n",
    "            noise_py_x = model(x, w_h, w_h2, w_o)\n",
    "\n",
    "            # reset the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # the cross-entropy loss function already contains the softmax\n",
    "            loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "\n",
    "            train_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            # compute the gradient\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss.append(np.mean(train_loss_this_epoch))\n",
    "\n",
    "        # test periodically\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "            print(f\"Mean Train Loss: {train_loss[-1]:.2e}\")\n",
    "            test_loss_this_epoch = []\n",
    "\n",
    "            # no need to compute gradients for validation\n",
    "            with torch.no_grad():\n",
    "                for idx, batch in enumerate(test_dataloader):\n",
    "                    x, y = batch\n",
    "                    x = x.reshape(batch_size, 784).to(device)\n",
    "                    noise_py_x = model(x, w_h, w_h2, w_o)\n",
    "\n",
    "                    loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "                    test_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            test_loss.append(np.mean(test_loss_this_epoch))\n",
    "\n",
    "            print(f\"Mean Test Loss:  {test_loss[-1]:.2e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_BASE_MODEL:\n",
    "    plt.plot(np.arange(n_epochs + 1), train_loss, label=\"Train\")\n",
    "    plt.plot(np.arange(1, n_epochs + 2, 2), test_loss, label=\"Test\")\n",
    "    plt.title(\"Train and Test Loss over Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dropout(X,p_drop=0.5):\n",
    "\n",
    "#     if p_drop > 1:\n",
    "#         return X\n",
    "\n",
    "#     mask = torch.bernoulli(torch.ones_like(X) * (1 - p_drop))\n",
    "#     return mask * X / (1 - p_drop)\n",
    "\n",
    "# def dropout_layer(X, dropout):\n",
    "#     assert 0 <= dropout <= 1\n",
    "#     if dropout == 1: return torch.zeros_like(X)\n",
    "#     mask = (torch.rand(X.shape) > dropout).float()\n",
    "#     return mask * X / (1.0 - dropout)\n",
    "\n",
    "# def dropout(X, p_drop=0.5):\n",
    "#     if 0 < p_drop < 1:\n",
    "#         dropout_mask = torch.random.binomial(1, 1 - p_drop, size=X.shape)\n",
    "#         X_dropout = X * dropout_mask / (1 - p_drop)\n",
    "#         return X_dropout\n",
    "#     else:\n",
    "#         return X\n",
    "    \n",
    "def dropout(X, p_drop=0.5):\n",
    "    if 0 < p_drop < 1:\n",
    "        dropout_mask = torch.bernoulli(torch.full(X.shape, 1 - p_drop)).to(X.device)\n",
    "        X_dropout = X * dropout_mask / (1 - p_drop)\n",
    "        return X_dropout\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_model(x, w_h, w_h2, w_o, p_drop_input=0,p_drop_hidden=0.2):\n",
    "    x = dropout(x, p_drop_input)\n",
    "    h = rectify(x @ w_h)\n",
    "    h = dropout(h, p_drop_hidden)\n",
    "    h2 = rectify(h @ w_h2)\n",
    "    h2 = dropout(h2, p_drop_hidden)\n",
    "    pre_softmax = h2 @ w_o\n",
    "    return pre_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_DROPOUT_MODEL:\n",
    "    # initialize weights\n",
    "    # input shape is (B, 784)\n",
    "    w_h_drop = init_weights((784, 625))\n",
    "    # hidden layer with 625 neurons\n",
    "    w_h2_drop = init_weights((625, 625))\n",
    "    # hidden layer with 625 neurons\n",
    "    w_o_drop = init_weights((625, 10))\n",
    "    # output shape is (B, 10)\n",
    "\n",
    "    optimizer = RMSprop(params=[w_h_drop, w_h2_drop, w_o_drop])\n",
    "\n",
    "    train_loss_drop = []\n",
    "    test_loss_drop = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prio/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025824022/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Mean Train Loss: 6.42e-01\n",
      "Mean Test Loss:  2.77e-01\n",
      "Epoch: 2\n",
      "Mean Train Loss: 4.09e-01\n",
      "Mean Test Loss:  1.72e-01\n",
      "Epoch: 4\n",
      "Mean Train Loss: 4.43e-01\n",
      "Mean Test Loss:  1.85e-01\n",
      "Epoch: 6\n",
      "Mean Train Loss: 4.87e-01\n",
      "Mean Test Loss:  1.88e-01\n",
      "Epoch: 8\n",
      "Mean Train Loss: 4.95e-01\n",
      "Mean Test Loss:  1.83e-01\n",
      "Epoch: 10\n",
      "Mean Train Loss: 5.35e-01\n",
      "Mean Test Loss:  2.09e-01\n",
      "Epoch: 12\n",
      "Mean Train Loss: 5.58e-01\n",
      "Mean Test Loss:  2.48e-01\n",
      "Epoch: 14\n",
      "Mean Train Loss: 5.85e-01\n",
      "Mean Test Loss:  2.51e-01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      4\u001b[0m     train_loss_this_epoch \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# our model requires flattened input\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/multiprocessing/connection.py:1135\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1135\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if TRAIN_DROPOUT_MODEL:\n",
    "    # put this into a training loop over 100 epochs\n",
    "    for epoch in range(n_epochs + 1):\n",
    "        train_loss_this_epoch = []\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            x, y = batch\n",
    "\n",
    "            # our model requires flattened input\n",
    "            x = x.reshape(batch_size, 784).to(device)\n",
    "            # feed input through model\n",
    "            noise_py_x = dropout_model(x, w_h_drop, w_h2_drop, w_o_drop)\n",
    "\n",
    "            # reset the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # the cross-entropy loss function already contains the softmax\n",
    "            loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "\n",
    "            train_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            # compute the gradient\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss_drop.append(np.mean(train_loss_this_epoch))\n",
    "\n",
    "        # test periodically\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "            print(f\"Mean Train Loss: {train_loss_drop[-1]:.2e}\")\n",
    "            test_loss_this_epoch = []\n",
    "\n",
    "            # no need to compute gradients for validation\n",
    "            with torch.no_grad():\n",
    "                for idx, batch in enumerate(test_dataloader):\n",
    "                    x, y = batch\n",
    "                    x = x.reshape(batch_size, 784).to(device)\n",
    "                    noise_py_x = dropout_model(x, w_h_drop, w_h2_drop, w_o_drop,0,0)\n",
    "\n",
    "                    loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "                    test_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            test_loss_drop.append(np.mean(test_loss_this_epoch))\n",
    "\n",
    "            print(f\"Mean Test Loss:  {test_loss_drop[-1]:.2e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAIN_DROPOUT_MODEL:\n",
    "    plt.plot(np.arange(n_epochs + 1), train_loss_drop, label=\"Train\")\n",
    "    plt.plot(np.arange(1, n_epochs + 2, 2), test_loss_drop, label=\"Test\")\n",
    "    plt.title(\"Train and Test Loss over Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dropout layer works by randomly deactivating certain neurons in the linear layers (or if applied to the input, deactivating certain features of the input vector). In this way the training load is more evenly distributed among the network, encourages diversity in the learned parameters and helps reduce redundancy i.e. neurons that do not significantly contribute to the performance of the network (cause of their existance can be attributed to overparametrization; see https://arxiv.org/abs/1503.02531, https://arxiv.org/abs/1803.03635).\n",
    "\n",
    "In our implementation we use all the neurons for the testing to get the best accuracy, so in this sense this is Inverted Dropout not dropout. See: https://stackoverflow.com/questions/54109617/implementing-dropout-from-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With dropout: 0.30725320733553085\n",
      "Without dropout: 0.4533351769449194\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_DROPOUT_MODEL and TRAIN_BASE_MODEL:\n",
    "    ## test error comparation\n",
    "    print(\"With dropout: {}\".format(test_loss_drop[-1]))\n",
    "    print(\"Without dropout: {}\".format(test_loss[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parametric Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRelu(X,a):\n",
    "    assert X.shape == a.shape\n",
    "\n",
    "    return torch.where(X > 0, X, a*X)\n",
    "\n",
    "# define the neural network\n",
    "def prelu_model(x, w_h, w_h2, w_o, a1, a2):\n",
    "    h = PRelu(x @ w_h,a1)\n",
    "    h2 = PRelu(h @ w_h2, a2)\n",
    "    pre_softmax = h2 @ w_o\n",
    "    return pre_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_PRELU_MODEL:\n",
    "    # initialize weights\n",
    "    # input shape is (B, 784)\n",
    "    w_h_prelu = init_weights((784, 625))\n",
    "    a1 = init_weights((batch_size,625))\n",
    "    # hidden layer with 625 neurons\n",
    "    w_h2_prelu = init_weights((625, 625))\n",
    "    a2 = init_weights((batch_size,625))\n",
    "    # hidden layer with 625 neurons\n",
    "    w_o_prelu = init_weights((625, 10))\n",
    "    # output shape is (B, 10)\n",
    "\n",
    "    optimizer = RMSprop(params=[w_h_prelu, w_h2_prelu, w_o_prelu,a1,a2])\n",
    "\n",
    "    train_loss_prelu = []\n",
    "    test_loss_prelu = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      4\u001b[0m     train_loss_this_epoch \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# our model requires flattened input\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/multiprocessing/connection.py:1135\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1135\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if TRAIN_PRELU_MODEL:\n",
    "    # put this into a training loop over 100 epochs\n",
    "    for epoch in range(n_epochs + 1):\n",
    "        train_loss_this_epoch = []\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            x, y = batch\n",
    "\n",
    "            # our model requires flattened input\n",
    "            x = x.reshape(batch_size, 784).to(device)\n",
    "            # feed input through model\n",
    "            noise_py_x = prelu_model(x, w_h_prelu, w_h2_prelu, w_o_prelu,a1,a2)\n",
    "\n",
    "            # reset the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # the cross-entropy loss function already contains the softmax\n",
    "            loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "\n",
    "            train_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            # compute the gradient\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss_prelu.append(np.mean(train_loss_this_epoch))\n",
    "\n",
    "        # test periodically\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "            print(f\"Mean Train Loss: {train_loss_prelu[-1]:.2e}\")\n",
    "            test_loss_this_epoch = []\n",
    "\n",
    "            # no need to compute gradients for validation\n",
    "            with torch.no_grad():\n",
    "                for idx, batch in enumerate(test_dataloader):\n",
    "                    x, y = batch\n",
    "                    x = x.reshape(batch_size, 784).to(device)\n",
    "                    noise_py_x = prelu_model(x, w_h_prelu, w_h2_prelu, w_o_prelu,a1,a2)\n",
    "\n",
    "                    loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "                    test_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            test_loss_prelu.append(np.mean(test_loss_this_epoch))\n",
    "\n",
    "            print(f\"Mean Test Loss:  {test_loss_prelu[-1]:.2e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_PRELU_MODEL:\n",
    "    plt.plot(np.arange(n_epochs + 1), train_loss_prelu, label=\"Train\")\n",
    "    plt.plot(np.arange(1, n_epochs + 2, 2), test_loss_prelu, label=\"Test\")\n",
    "    plt.title(\"Train and Test Loss over Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LENET:\n",
    "    hyperparams = {\n",
    "        'length': 3,\n",
    "        'f': [32,64,128],\n",
    "        'pic_in': [1,32,64],\n",
    "        'k_x': [5,5,3],\n",
    "        'k_y': [5,5,3]\n",
    "    }\n",
    "\n",
    "    weight_vectors = [init_weights((hyperparams['f'][i],hyperparams['pic_in'][i],hyperparams['k_x'][i],hyperparams['k_y'][i])) for i in range(3)]\n",
    "\n",
    "    number_of_output_pixel = 128 # chat gpt answer\n",
    "    # hidden layer with 625 neurons\n",
    "    w_h2 = init_weights((number_of_output_pixel, 625))\n",
    "    # hidden layer with 625 neurons\n",
    "    w_o = init_weights((625, 10))\n",
    "    # output shape is (B, 10)\n",
    "\n",
    "    optimizer = RMSprop(params=[w_h2,w_o,*weight_vectors])\n",
    "\n",
    "    train_loss_lenet = []\n",
    "    test_loss_lenet = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leNet(X,weight_vectors,w_h2,w_o,p_drop_input):\n",
    "    '''\n",
    "    x: (batch,1,28,28)\n",
    "    '''\n",
    "    conv1 = rectify(conv2d(X,weight_vectors[0]))\n",
    "    subsampling_layer = max_pool2d(conv1,(2,2))\n",
    "    out_layer = dropout(subsampling_layer,p_drop_input)\n",
    "\n",
    "    conv2 = rectify(conv2d(out_layer,weight_vectors[1]))\n",
    "    subsampling_layer_2 = max_pool2d(conv2,(2,2))\n",
    "    out_layer_2 = dropout(subsampling_layer_2,p_drop_input)\n",
    "\n",
    "    conv3 = rectify(conv2d(out_layer_2,weight_vectors[2]))\n",
    "    subsampling_layer_3 = max_pool2d(conv3,(2,2))\n",
    "    out_layer_3 = dropout(subsampling_layer_3,p_drop_input)\n",
    "\n",
    "    # print(out_layer_3.shape)\n",
    "\n",
    "    flattened_out = out_layer_3.reshape(batch_size,-1)\n",
    "\n",
    "    # print(flattened_out.shape)\n",
    "\n",
    "    h2 = rectify(flattened_out @ w_h2)\n",
    "    pre_softmax = h2 @ w_o\n",
    "\n",
    "    return pre_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lenet(image,filters):\n",
    "    '''\n",
    "    plots:\n",
    "    - original test image\n",
    "    - image after 3 filters from the conv1 applied to it (in parallel)\n",
    "    - filter weights as images\n",
    "    '''\n",
    "    # Perform convolution using the selected filters\n",
    "    conv_results = []\n",
    "    for i in range(3):\n",
    "        conv_result = conv2d(image.unsqueeze(0), filters[i].unsqueeze(0))\n",
    "        conv_results.append(conv_result.cpu().squeeze().detach().numpy())\n",
    "\n",
    "    # Convert the image and filters to numpy arrays for plotting\n",
    "    image_np = image.cpu().squeeze().numpy()\n",
    "    filters_np = filters.detach().cpu().squeeze().numpy()\n",
    "\n",
    "    print(filters_np.shape)\n",
    "\n",
    "    # Plot the results\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "\n",
    "    # Plot the filter weights and convolved images\n",
    "    for i in range(3):\n",
    "        # Plot the original image\n",
    "        axs[i, 0].imshow(image_np, cmap='gray')\n",
    "        axs[i, 0].set_title(\"Original Image\")\n",
    "\n",
    "\n",
    "        # Plot filter weights\n",
    "        axs[i, 1].imshow(filters_np[i], cmap='viridis')\n",
    "        axs[i, 1].set_title(f\"Filter {i + 1} Weights\")\n",
    "\n",
    "        # Plot convolved image\n",
    "        axs[i, 2].imshow(conv_results[i], cmap='viridis')\n",
    "        axs[i, 2].set_title(f\"Convolution with Filter {i + 1}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LENET:\n",
    "    # put this into a training loop over 100 epochs\n",
    "    for epoch in range(n_epochs + 1):\n",
    "        train_loss_this_epoch = []\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            x, y = batch\n",
    "\n",
    "            # our model requires flattened input\n",
    "            x = x.to(device)\n",
    "            # feed input through model\n",
    "            noise_py_x = leNet(x,weight_vectors,w_h2,w_o,0.5)\n",
    "\n",
    "            # reset the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # the cross-entropy loss function already contains the softmax\n",
    "            loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "\n",
    "            train_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            # compute the gradient\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss_lenet.append(np.mean(train_loss_this_epoch))\n",
    "\n",
    "        # test periodically\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "            print(f\"Mean Train Loss: {train_loss_lenet[-1]:.2e}\")\n",
    "            test_loss_this_epoch = []\n",
    "\n",
    "            # no need to compute gradients for validation\n",
    "            with torch.no_grad():\n",
    "                for idx, batch in enumerate(test_dataloader):\n",
    "                    x, y = batch\n",
    "                    x = x.to(device)\n",
    "                    noise_py_x = leNet(x,weight_vectors,w_h2,w_o,0)\n",
    "\n",
    "                    loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "                    test_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            test_loss_lenet.append(np.mean(test_loss_this_epoch))\n",
    "\n",
    "            print(f\"Mean Test Loss:  {test_loss_lenet[-1]:.2e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LENET:\n",
    "    plt.plot(np.arange(n_epochs + 1), train_loss_lenet, label=\"Train\")\n",
    "    plt.plot(np.arange(1, n_epochs + 2, 2), test_loss_lenet, label=\"Test\")\n",
    "    plt.title(\"Train and Test Loss over Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LENET:\n",
    "    data_iter = iter(test_dataloader)\n",
    "    images, labels = next(data_iter)\n",
    "\n",
    "    image = images[25]\n",
    "    filters = weight_vectors[0][:3]\n",
    "\n",
    "    plot_lenet(image.to(device),filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2: Applying a random linear shift to the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomLinearShift(object):\n",
    "    def __init__(self, shift_range=(-0.5, 0.5)):\n",
    "        self.shift_range = shift_range\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        shift = np.random.uniform(self.shift_range[0], self.shift_range[1])\n",
    "        return tensor + shift\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + f'(shift_range={self.shift_range})'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 100\n",
    "\n",
    "# transform images into normalized tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "transform_extended = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    RandomLinearShift(shift_range=(-0.5,0.5))\n",
    "]) \n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    \"./\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    \"./\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "    ]),\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LENET_SHIFT:\n",
    "    hyperparams = {\n",
    "        'length': 3,\n",
    "        'f': [32,64,128],\n",
    "        'pic_in': [1,32,64],\n",
    "        'k_x': [5,5,3],\n",
    "        'k_y': [5,5,3]\n",
    "    }\n",
    "\n",
    "    weight_vectors = [init_weights((hyperparams['f'][i],hyperparams['pic_in'][i],hyperparams['k_x'][i],hyperparams['k_y'][i])) for i in range(3)]\n",
    "\n",
    "    number_of_output_pixel = 128 # chat gpt answer\n",
    "    # hidden layer with 625 neurons\n",
    "    w_h2 = init_weights((number_of_output_pixel, 625))\n",
    "    # hidden layer with 625 neurons\n",
    "    w_o = init_weights((625, 10))\n",
    "    # output shape is (B, 10)\n",
    "\n",
    "    optimizer = RMSprop(params=[w_h2,w_o,*weight_vectors])\n",
    "\n",
    "    train_loss_lenet_shift = []\n",
    "    test_loss_lenet_shift = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LENET_SHIFT:\n",
    "    # put this into a training loop over 100 epochs\n",
    "    for epoch in range(n_epochs + 1):\n",
    "        train_loss_this_epoch = []\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            x, y = batch\n",
    "\n",
    "            # our model requires flattened input\n",
    "            x = x.to(device)\n",
    "            # feed input through model\n",
    "            noise_py_x = leNet(x,weight_vectors,w_h2,w_o,0.5)\n",
    "\n",
    "            # reset the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # the cross-entropy loss function already contains the softmax\n",
    "            loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "\n",
    "            train_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            # compute the gradient\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss_lenet_shift.append(np.mean(train_loss_this_epoch))\n",
    "\n",
    "        # test periodically\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "            print(f\"Mean Train Loss: {train_loss_lenet_shift[-1]:.2e}\")\n",
    "            test_loss_this_epoch = []\n",
    "\n",
    "            # no need to compute gradients for validation\n",
    "            with torch.no_grad():\n",
    "                for idx, batch in enumerate(test_dataloader):\n",
    "                    x, y = batch\n",
    "                    x = x.to(device)\n",
    "                    noise_py_x = leNet(x,weight_vectors,w_h2,w_o,0.0)\n",
    "\n",
    "                    loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "                    test_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            test_loss_lenet_shift.append(np.mean(test_loss_this_epoch))\n",
    "\n",
    "            print(f\"Mean Test Loss:  {test_loss_lenet_shift[-1]:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LENET_SHIFT:\n",
    "    plt.plot(np.arange(n_epochs + 1), train_loss_lenet_shift, label=\"Train\")\n",
    "    plt.plot(np.arange(1, n_epochs + 2, 2), test_loss_lenet_shift, label=\"Test\")\n",
    "    plt.title(\"Train and Test Loss over Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LENET_SHIFT:\n",
    "    data_iter = iter(test_dataloader)\n",
    "    images, labels = next(data_iter)\n",
    "\n",
    "    image = images[25]\n",
    "    filters = weight_vectors[0][:3]\n",
    "\n",
    "    plot_lenet(image.to(device),filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if ALL:\n",
    "\n",
    "    data = {\n",
    "        'architecture': ['base', 'dropout', 'prelu', 'lenet', 'lenet + shift'],\n",
    "        'test_loss': [test_loss[-1],test_loss_drop[-1],test_loss_prelu[-1],test_loss_lenet[-1],test_loss_lenet_shift[-1]],\n",
    "        'train_loss': [train_loss[-1],train_loss_drop[-1],train_loss_prelu[-1],train_loss_lenet[-1],train_loss_lenet_shift[-1]]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    print(\"Number of epochs: {}\".format(n_epochs))\n",
    "    print(\"Learning rate: {}\".format(1e-3))\n",
    "    print(\"Batch size {}\".format(batch_size))\n",
    "    print(\"Dropout rate (dropout model + lenet + lenet with shift) {}\".format(0.5))\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that regularization techniques (dropout, random shift) help with overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
