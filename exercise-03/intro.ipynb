{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name, matrikelnummer\n",
    "\n",
    "Prioteasa Cristi Andrei, 4740844 \\\n",
    "..., ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.nn.functional import conv2d, max_pool2d, cross_entropy\n",
    "\n",
    "plt.rc(\"figure\", dpi=100)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BASE_MODEL = False\n",
    "TRAIN_DROPOUT_MODEL = True\n",
    "TRAIN_PRELU_MODEL = False\n",
    "TRAIN_LENET = False\n",
    "TRAIN_LENET_SHIFT = False\n",
    "\n",
    "ALL = TRAIN_BASE_MODEL and TRAIN_DROPOUT_MODEL and TRAIN_PRELU_MODEL and TRAIN_LENET and TRAIN_LENET_SHIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "# transform images into normalized tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "transform_extended = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "]) \n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    \"./\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    \"./\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    # Kaiming He initialization (a good initialization is important)\n",
    "    # https://arxiv.org/abs/1502.01852\n",
    "    std = np.sqrt(2. / shape[0])\n",
    "    w = torch.randn(size=shape).to(device) * std\n",
    "    w.requires_grad = True\n",
    "    return w\n",
    "\n",
    "\n",
    "def rectify(x):\n",
    "    # Rectified Linear Unit (ReLU)\n",
    "    return torch.max(torch.zeros_like(x), x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSprop(optim.Optimizer):\n",
    "    \"\"\"\n",
    "    This is a reduced version of the PyTorch internal RMSprop optimizer\n",
    "    It serves here as an example\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr=1e-3, alpha=0.5, eps=1e-8):\n",
    "        defaults = dict(lr=lr, alpha=alpha, eps=eps)\n",
    "        super(RMSprop, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self):\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                grad = p.grad.data.to(device)\n",
    "                state = self.state[p]\n",
    "\n",
    "                # state initialization\n",
    "                if len(state) == 0:\n",
    "                    state['square_avg'] = torch.zeros_like(p.data)\n",
    "\n",
    "                square_avg = state['square_avg']\n",
    "                alpha = group['alpha']\n",
    "\n",
    "                # update running averages\n",
    "                square_avg.mul_(alpha).addcmul_(grad, grad, value=1 - alpha)\n",
    "                avg = square_avg.sqrt().add_(group['eps'])\n",
    "\n",
    "                # gradient update\n",
    "                p.data.addcdiv_(grad, avg, value=-group['lr'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the neural network\n",
    "def model(x, w_h, w_h2, w_o):\n",
    "    h = rectify(x @ w_h)\n",
    "    h2 = rectify(h @ w_h2)\n",
    "    pre_softmax = h2 @ w_o\n",
    "    return pre_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_BASE_MODEL:\n",
    "\n",
    "    # initialize weights\n",
    "    # input shape is (B, 784)\n",
    "    w_h = init_weights((784, 625))\n",
    "    # hidden layer with 625 neurons\n",
    "    w_h2 = init_weights((625, 625))\n",
    "    # hidden layer with 625 neurons\n",
    "    w_o = init_weights((625, 10))\n",
    "    # output shape is (B, 10)\n",
    "\n",
    "\n",
    "    optimizer = RMSprop(params=[w_h, w_h2, w_o])\n",
    "\n",
    "    train_loss = []\n",
    "    test_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_BASE_MODEL:\n",
    "    # put this into a training loop over 100 epochs\n",
    "    for epoch in range(n_epochs + 1):\n",
    "        train_loss_this_epoch = []\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            x, y = batch\n",
    "\n",
    "            # our model requires flattened input\n",
    "            x = x.reshape(batch_size, 784).to(device)\n",
    "            # feed input through model\n",
    "            noise_py_x = model(x, w_h, w_h2, w_o)\n",
    "\n",
    "            # reset the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # the cross-entropy loss function already contains the softmax\n",
    "            loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "\n",
    "            train_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            # compute the gradient\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss.append(np.mean(train_loss_this_epoch))\n",
    "\n",
    "        # test periodically\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "            print(f\"Mean Train Loss: {train_loss[-1]:.2e}\")\n",
    "            test_loss_this_epoch = []\n",
    "\n",
    "            # no need to compute gradients for validation\n",
    "            with torch.no_grad():\n",
    "                for idx, batch in enumerate(test_dataloader):\n",
    "                    x, y = batch\n",
    "                    x = x.reshape(batch_size, 784).to(device)\n",
    "                    noise_py_x = model(x, w_h, w_h2, w_o)\n",
    "\n",
    "                    loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "                    test_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            test_loss.append(np.mean(test_loss_this_epoch))\n",
    "\n",
    "            print(f\"Mean Test Loss:  {test_loss[-1]:.2e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_BASE_MODEL:\n",
    "    plt.plot(np.arange(n_epochs + 1), train_loss, label=\"Train\")\n",
    "    plt.plot(np.arange(1, n_epochs + 2, 2), test_loss, label=\"Test\")\n",
    "    plt.title(\"Train and Test Loss over Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dropout(X,p_drop=0.5):\n",
    "\n",
    "#     if p_drop > 1:\n",
    "#         return X\n",
    "\n",
    "#     mask = torch.bernoulli(torch.ones_like(X) * (1 - p_drop))\n",
    "#     return mask * X / (1 - p_drop)\n",
    "\n",
    "# def dropout_layer(X, dropout):\n",
    "#     assert 0 <= dropout <= 1\n",
    "#     if dropout == 1: return torch.zeros_like(X)\n",
    "#     mask = (torch.rand(X.shape) > dropout).float()\n",
    "#     return mask * X / (1.0 - dropout)\n",
    "\n",
    "# def dropout(X, p_drop=0.5):\n",
    "#     if 0 < p_drop < 1:\n",
    "#         dropout_mask = torch.random.binomial(1, 1 - p_drop, size=X.shape)\n",
    "#         X_dropout = X * dropout_mask / (1 - p_drop)\n",
    "#         return X_dropout\n",
    "#     else:\n",
    "#         return X\n",
    "    \n",
    "def dropout(X, p_drop=0.5):\n",
    "    if 0 < p_drop < 1:\n",
    "        dropout_mask = torch.bernoulli(torch.full(X.shape, 1 - p_drop)).to(X.device)\n",
    "        X_dropout = X * dropout_mask / (1 - p_drop)\n",
    "        return X_dropout\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_model(x, w_h, w_h2, w_o, p_drop_input=0,p_drop_hidden=0.2):\n",
    "    x = dropout(x, p_drop_input)\n",
    "    h = rectify(x @ w_h)\n",
    "    h = dropout(h, p_drop_hidden)\n",
    "    h2 = rectify(h @ w_h2)\n",
    "    h2 = dropout(h2, p_drop_hidden)\n",
    "    pre_softmax = h2 @ w_o\n",
    "    return pre_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_DROPOUT_MODEL:\n",
    "    # initialize weights\n",
    "    # input shape is (B, 784)\n",
    "    w_h_drop = init_weights((784, 625))\n",
    "    # hidden layer with 625 neurons\n",
    "    w_h2_drop = init_weights((625, 625))\n",
    "    # hidden layer with 625 neurons\n",
    "    w_o_drop = init_weights((625, 10))\n",
    "    # output shape is (B, 10)\n",
    "\n",
    "    optimizer = RMSprop(params=[w_h_drop, w_h2_drop, w_o_drop])\n",
    "\n",
    "    train_loss_drop = []\n",
    "    test_loss_drop = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Mean Train Loss: 4.59e-01\n",
      "Mean Test Loss:  1.95e-01\n",
      "Epoch: 2\n",
      "Mean Train Loss: 2.59e-01\n",
      "Mean Test Loss:  1.60e-01\n",
      "Epoch: 4\n",
      "Mean Train Loss: 2.62e-01\n",
      "Mean Test Loss:  1.65e-01\n",
      "Epoch: 6\n",
      "Mean Train Loss: 2.77e-01\n",
      "Mean Test Loss:  1.75e-01\n",
      "Epoch: 8\n",
      "Mean Train Loss: 2.69e-01\n",
      "Mean Test Loss:  2.16e-01\n",
      "Epoch: 10\n",
      "Mean Train Loss: 2.57e-01\n",
      "Mean Test Loss:  2.32e-01\n",
      "Epoch: 12\n",
      "Mean Train Loss: 2.65e-01\n",
      "Mean Test Loss:  2.22e-01\n",
      "Epoch: 14\n",
      "Mean Train Loss: 2.64e-01\n",
      "Mean Test Loss:  2.54e-01\n",
      "Epoch: 16\n",
      "Mean Train Loss: 2.77e-01\n",
      "Mean Test Loss:  2.64e-01\n",
      "Epoch: 18\n",
      "Mean Train Loss: 2.55e-01\n",
      "Mean Test Loss:  3.64e-01\n",
      "Epoch: 20\n",
      "Mean Train Loss: 2.47e-01\n",
      "Mean Test Loss:  3.60e-01\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_DROPOUT_MODEL:\n",
    "    # put this into a training loop over 100 epochs\n",
    "    for epoch in range(n_epochs + 1):\n",
    "        train_loss_this_epoch = []\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            x, y = batch\n",
    "\n",
    "            # our model requires flattened input\n",
    "            x = x.reshape(batch_size, 784).to(device)\n",
    "            # feed input through model\n",
    "            noise_py_x = dropout_model(x, w_h_drop, w_h2_drop, w_o_drop)\n",
    "\n",
    "            # reset the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # the cross-entropy loss function already contains the softmax\n",
    "            loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "\n",
    "            train_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            # compute the gradient\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss_drop.append(np.mean(train_loss_this_epoch))\n",
    "\n",
    "        # test periodically\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "            print(f\"Mean Train Loss: {train_loss_drop[-1]:.2e}\")\n",
    "            test_loss_this_epoch = []\n",
    "\n",
    "            # no need to compute gradients for validation\n",
    "            with torch.no_grad():\n",
    "                for idx, batch in enumerate(test_dataloader):\n",
    "                    x, y = batch\n",
    "                    x = x.reshape(batch_size, 784).to(device)\n",
    "                    noise_py_x = dropout_model(x, w_h_drop, w_h2_drop, w_o_drop,0,0)\n",
    "\n",
    "                    loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "                    test_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            test_loss_drop.append(np.mean(test_loss_this_epoch))\n",
    "\n",
    "            print(f\"Mean Test Loss:  {test_loss_drop[-1]:.2e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAIN_DROPOUT_MODEL:\n",
    "    plt.plot(np.arange(n_epochs + 1), train_loss_drop, label=\"Train\")\n",
    "    plt.plot(np.arange(1, n_epochs + 2, 2), test_loss_drop, label=\"Test\")\n",
    "    plt.title(\"Train and Test Loss over Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dropout layer works by randomly deactivating certain neurons in the linear layers (or if applied to the input, deactivating certain features of the input vector). In this way the training load is more evenly distributed among the network, encourages diversity in the learned parameters and helps reduce redundancy i.e. neurons that do not significantly contribute to the performance of the network (cause of their existance can be attributed to overparametrization; see https://arxiv.org/abs/1503.02531, https://arxiv.org/abs/1803.03635).\n",
    "\n",
    "In our implementation we use all the neurons for the testing to get the best accuracy, so in this sense this is Inverted Dropout not dropout. See: https://stackoverflow.com/questions/54109617/implementing-dropout-from-scratch\n",
    "\n",
    "A dropout rate of 0.5 seemed to be to big and stopped the model from converging. We try different dropout rates and see that 0.2 offers a good convergence, given the learning rate.\n",
    "\n",
    "The model still overfits on the test data, but the overfitting is delayed and reduced by using dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_DROPOUT_MODEL and TRAIN_BASE_MODEL:\n",
    "    ## test error comparation\n",
    "    print(\"With dropout: {}\".format(test_loss_drop[-1]))\n",
    "    print(\"Without dropout: {}\".format(test_loss[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parametric Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRelu(X,a):\n",
    "    assert X.shape == a.shape\n",
    "\n",
    "    return torch.where(X > 0, X, a*X)\n",
    "\n",
    "# define the neural network\n",
    "def prelu_model(x, w_h, w_h2, w_o, a1, a2):\n",
    "    h = PRelu(x @ w_h,a1)\n",
    "    h2 = PRelu(h @ w_h2, a2)\n",
    "    pre_softmax = h2 @ w_o\n",
    "    return pre_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_PRELU_MODEL:\n",
    "    # initialize weights\n",
    "    # input shape is (B, 784)\n",
    "    w_h_prelu = init_weights((784, 625))\n",
    "    a1 = init_weights((batch_size,625))\n",
    "    # hidden layer with 625 neurons\n",
    "    w_h2_prelu = init_weights((625, 625))\n",
    "    a2 = init_weights((batch_size,625))\n",
    "    # hidden layer with 625 neurons\n",
    "    w_o_prelu = init_weights((625, 10))\n",
    "    # output shape is (B, 10)\n",
    "\n",
    "    optimizer = RMSprop(params=[w_h_prelu, w_h2_prelu, w_o_prelu,a1,a2])\n",
    "\n",
    "    train_loss_prelu = []\n",
    "    test_loss_prelu = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_PRELU_MODEL:\n",
    "    # put this into a training loop over 100 epochs\n",
    "    for epoch in range(n_epochs + 1):\n",
    "        train_loss_this_epoch = []\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            x, y = batch\n",
    "\n",
    "            # our model requires flattened input\n",
    "            x = x.reshape(batch_size, 784).to(device)\n",
    "            # feed input through model\n",
    "            noise_py_x = prelu_model(x, w_h_prelu, w_h2_prelu, w_o_prelu,a1,a2)\n",
    "\n",
    "            # reset the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # the cross-entropy loss function already contains the softmax\n",
    "            loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "\n",
    "            train_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            # compute the gradient\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss_prelu.append(np.mean(train_loss_this_epoch))\n",
    "\n",
    "        # test periodically\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "            print(f\"Mean Train Loss: {train_loss_prelu[-1]:.2e}\")\n",
    "            test_loss_this_epoch = []\n",
    "\n",
    "            # no need to compute gradients for validation\n",
    "            with torch.no_grad():\n",
    "                for idx, batch in enumerate(test_dataloader):\n",
    "                    x, y = batch\n",
    "                    x = x.reshape(batch_size, 784).to(device)\n",
    "                    noise_py_x = prelu_model(x, w_h_prelu, w_h2_prelu, w_o_prelu,a1,a2)\n",
    "\n",
    "                    loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "                    test_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            test_loss_prelu.append(np.mean(test_loss_this_epoch))\n",
    "\n",
    "            print(f\"Mean Test Loss:  {test_loss_prelu[-1]:.2e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_PRELU_MODEL:\n",
    "    plt.plot(np.arange(n_epochs + 1), train_loss_prelu, label=\"Train\")\n",
    "    plt.plot(np.arange(1, n_epochs + 2, 2), test_loss_prelu, label=\"Test\")\n",
    "    plt.title(\"Train and Test Loss over Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LENET:\n",
    "    hyperparams = {\n",
    "        'length': 3,\n",
    "        'f': [32,64,128],\n",
    "        'pic_in': [1,32,64],\n",
    "        'k_x': [5,5,3],\n",
    "        'k_y': [5,5,3]\n",
    "    }\n",
    "\n",
    "    weight_vectors = [init_weights((hyperparams['f'][i],hyperparams['pic_in'][i],hyperparams['k_x'][i],hyperparams['k_y'][i])) for i in range(3)]\n",
    "\n",
    "    number_of_output_pixel = 128 # chat gpt answer\n",
    "    # hidden layer with 625 neurons\n",
    "    w_h2 = init_weights((number_of_output_pixel, 625))\n",
    "    # hidden layer with 625 neurons\n",
    "    w_o = init_weights((625, 10))\n",
    "    # output shape is (B, 10)\n",
    "\n",
    "    optimizer = RMSprop(params=[w_h2,w_o,*weight_vectors])\n",
    "\n",
    "    train_loss_lenet = []\n",
    "    test_loss_lenet = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leNet(X,weight_vectors,w_h2,w_o,p_drop_input):\n",
    "    '''\n",
    "    x: (batch,1,28,28)\n",
    "    '''\n",
    "    conv1 = rectify(conv2d(X,weight_vectors[0]))\n",
    "    subsampling_layer = max_pool2d(conv1,(2,2))\n",
    "    out_layer = dropout(subsampling_layer,p_drop_input)\n",
    "\n",
    "    conv2 = rectify(conv2d(out_layer,weight_vectors[1]))\n",
    "    subsampling_layer_2 = max_pool2d(conv2,(2,2))\n",
    "    out_layer_2 = dropout(subsampling_layer_2,p_drop_input)\n",
    "\n",
    "    conv3 = rectify(conv2d(out_layer_2,weight_vectors[2]))\n",
    "    subsampling_layer_3 = max_pool2d(conv3,(2,2))\n",
    "    out_layer_3 = dropout(subsampling_layer_3,p_drop_input)\n",
    "\n",
    "    # print(out_layer_3.shape)\n",
    "\n",
    "    flattened_out = out_layer_3.reshape(batch_size,-1)\n",
    "\n",
    "    # print(flattened_out.shape)\n",
    "\n",
    "    h2 = rectify(flattened_out @ w_h2)\n",
    "    pre_softmax = h2 @ w_o\n",
    "\n",
    "    return pre_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lenet(image,filters):\n",
    "    '''\n",
    "    plots:\n",
    "    - original test image\n",
    "    - image after 3 filters from the conv1 applied to it (in parallel)\n",
    "    - filter weights as images\n",
    "    '''\n",
    "    # Perform convolution using the selected filters\n",
    "    conv_results = []\n",
    "    for i in range(3):\n",
    "        conv_result = conv2d(image.unsqueeze(0), filters[i].unsqueeze(0))\n",
    "        conv_results.append(conv_result.cpu().squeeze().detach().numpy())\n",
    "\n",
    "    # Convert the image and filters to numpy arrays for plotting\n",
    "    image_np = image.cpu().squeeze().numpy()\n",
    "    filters_np = filters.detach().cpu().squeeze().numpy()\n",
    "\n",
    "    print(filters_np.shape)\n",
    "\n",
    "    # Plot the results\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "\n",
    "    # Plot the filter weights and convolved images\n",
    "    for i in range(3):\n",
    "        # Plot the original image\n",
    "        axs[i, 0].imshow(image_np, cmap='gray')\n",
    "        axs[i, 0].set_title(\"Original Image\")\n",
    "\n",
    "\n",
    "        # Plot filter weights\n",
    "        axs[i, 1].imshow(filters_np[i], cmap='viridis')\n",
    "        axs[i, 1].set_title(f\"Filter {i + 1} Weights\")\n",
    "\n",
    "        # Plot convolved image\n",
    "        axs[i, 2].imshow(conv_results[i], cmap='viridis')\n",
    "        axs[i, 2].set_title(f\"Convolution with Filter {i + 1}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LENET:\n",
    "    # put this into a training loop over 100 epochs\n",
    "    for epoch in range(n_epochs + 1):\n",
    "        train_loss_this_epoch = []\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            x, y = batch\n",
    "\n",
    "            # our model requires flattened input\n",
    "            x = x.to(device)\n",
    "            # feed input through model\n",
    "            noise_py_x = leNet(x,weight_vectors,w_h2,w_o,0.5)\n",
    "\n",
    "            # reset the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # the cross-entropy loss function already contains the softmax\n",
    "            loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "\n",
    "            train_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            # compute the gradient\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss_lenet.append(np.mean(train_loss_this_epoch))\n",
    "\n",
    "        # test periodically\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "            print(f\"Mean Train Loss: {train_loss_lenet[-1]:.2e}\")\n",
    "            test_loss_this_epoch = []\n",
    "\n",
    "            # no need to compute gradients for validation\n",
    "            with torch.no_grad():\n",
    "                for idx, batch in enumerate(test_dataloader):\n",
    "                    x, y = batch\n",
    "                    x = x.to(device)\n",
    "                    noise_py_x = leNet(x,weight_vectors,w_h2,w_o,0)\n",
    "\n",
    "                    loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "                    test_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            test_loss_lenet.append(np.mean(test_loss_this_epoch))\n",
    "\n",
    "            print(f\"Mean Test Loss:  {test_loss_lenet[-1]:.2e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LENET:\n",
    "    plt.plot(np.arange(n_epochs + 1), train_loss_lenet, label=\"Train\")\n",
    "    plt.plot(np.arange(1, n_epochs + 2, 2), test_loss_lenet, label=\"Test\")\n",
    "    plt.title(\"Train and Test Loss over Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LENET:\n",
    "    data_iter = iter(test_dataloader)\n",
    "    images, labels = next(data_iter)\n",
    "\n",
    "    image = images[25]\n",
    "    filters = weight_vectors[0][:3]\n",
    "\n",
    "    plot_lenet(image.to(device),filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2: Applying a random linear shift to the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomLinearShift(object):\n",
    "    def __init__(self, shift_range=(-0.5, 0.5)):\n",
    "        self.shift_range = shift_range\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        shift = np.random.uniform(self.shift_range[0], self.shift_range[1])\n",
    "        return tensor + shift\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + f'(shift_range={self.shift_range})'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 100\n",
    "\n",
    "# transform images into normalized tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "transform_extended = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    RandomLinearShift(shift_range=(-0.5,0.5))\n",
    "]) \n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    \"./\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    \"./\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "    ]),\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LENET_SHIFT:\n",
    "    hyperparams = {\n",
    "        'length': 3,\n",
    "        'f': [32,64,128],\n",
    "        'pic_in': [1,32,64],\n",
    "        'k_x': [5,5,3],\n",
    "        'k_y': [5,5,3]\n",
    "    }\n",
    "\n",
    "    weight_vectors = [init_weights((hyperparams['f'][i],hyperparams['pic_in'][i],hyperparams['k_x'][i],hyperparams['k_y'][i])) for i in range(3)]\n",
    "\n",
    "    number_of_output_pixel = 128 # chat gpt answer\n",
    "    # hidden layer with 625 neurons\n",
    "    w_h2 = init_weights((number_of_output_pixel, 625))\n",
    "    # hidden layer with 625 neurons\n",
    "    w_o = init_weights((625, 10))\n",
    "    # output shape is (B, 10)\n",
    "\n",
    "    optimizer = RMSprop(params=[w_h2,w_o,*weight_vectors])\n",
    "\n",
    "    train_loss_lenet_shift = []\n",
    "    test_loss_lenet_shift = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LENET_SHIFT:\n",
    "    # put this into a training loop over 100 epochs\n",
    "    for epoch in range(n_epochs + 1):\n",
    "        train_loss_this_epoch = []\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            x, y = batch\n",
    "\n",
    "            # our model requires flattened input\n",
    "            x = x.to(device)\n",
    "            # feed input through model\n",
    "            noise_py_x = leNet(x,weight_vectors,w_h2,w_o,0.5)\n",
    "\n",
    "            # reset the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # the cross-entropy loss function already contains the softmax\n",
    "            loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "\n",
    "            train_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            # compute the gradient\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss_lenet_shift.append(np.mean(train_loss_this_epoch))\n",
    "\n",
    "        # test periodically\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "            print(f\"Mean Train Loss: {train_loss_lenet_shift[-1]:.2e}\")\n",
    "            test_loss_this_epoch = []\n",
    "\n",
    "            # no need to compute gradients for validation\n",
    "            with torch.no_grad():\n",
    "                for idx, batch in enumerate(test_dataloader):\n",
    "                    x, y = batch\n",
    "                    x = x.to(device)\n",
    "                    noise_py_x = leNet(x,weight_vectors,w_h2,w_o,0.0)\n",
    "\n",
    "                    loss = cross_entropy(noise_py_x, y.to(device), reduction=\"mean\")\n",
    "                    test_loss_this_epoch.append(float(loss))\n",
    "\n",
    "            test_loss_lenet_shift.append(np.mean(test_loss_this_epoch))\n",
    "\n",
    "            print(f\"Mean Test Loss:  {test_loss_lenet_shift[-1]:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LENET_SHIFT:\n",
    "    plt.plot(np.arange(n_epochs + 1), train_loss_lenet_shift, label=\"Train\")\n",
    "    plt.plot(np.arange(1, n_epochs + 2, 2), test_loss_lenet_shift, label=\"Test\")\n",
    "    plt.title(\"Train and Test Loss over Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_LENET_SHIFT:\n",
    "    data_iter = iter(test_dataloader)\n",
    "    images, labels = next(data_iter)\n",
    "\n",
    "    image = images[25]\n",
    "    filters = weight_vectors[0][:3]\n",
    "\n",
    "    plot_lenet(image.to(device),filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if ALL:\n",
    "\n",
    "    data = {\n",
    "        'architecture': ['base', 'dropout', 'prelu', 'lenet', 'lenet + shift'],\n",
    "        'test_loss': [test_loss[-1],test_loss_drop[-1],test_loss_prelu[-1],test_loss_lenet[-1],test_loss_lenet_shift[-1]],\n",
    "        'train_loss': [train_loss[-1],train_loss_drop[-1],train_loss_prelu[-1],train_loss_lenet[-1],train_loss_lenet_shift[-1]]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    print(\"Number of epochs: {}\".format(n_epochs))\n",
    "    print(\"Learning rate: {}\".format(1e-3))\n",
    "    print(\"Batch size {}\".format(batch_size))\n",
    "    print(\"Dropout rate (dropout model + lenet + lenet with shift) {}\".format(0.5))\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that regularization techniques (dropout, random shift) help with overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
